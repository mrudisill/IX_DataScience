{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#eb3483'> Predicting Time Series </font>\n",
    "\n",
    "We have seen ways to decompose and model time series. The next step of course, is to **forecast the future**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(16,5)})\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import gauss\n",
    "from random import seed\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_airlines_series\n",
    "from utils import load_electricity_consumption_series\n",
    "from utils import load_shampoo_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#eb3483'>White Noise vs. Signal  </font>\n",
    "\n",
    "We are going to generate some datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysterious_data_1 = load_electricity_consumption_series()['consumption']\n",
    "mysterious_data_2 = pd.Series([gauss(0.0, 1.0) for i in range(1000)])\n",
    "mysterious_data_2.name = 'White noise'\n",
    "mysterious_data_2.index = pd.date_range(pd.datetime(1971, 12, 25, hour=12, minute=0), periods=1000, freq='3d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timeseries are sneaky things. Sometimes noise looks like data, and data looks like noise. \n",
    "\n",
    "A frequent problem with timeseries is answering the open, yet crucial question: _\"is there any kind of signal here?\"_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysterious_data_1.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysterious_data_2.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This already gives us a visual clue that we seem to have more structure in the first one.\n",
    "\n",
    "We can continue to search for structure by decomposing the signal, as you've learned in the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = seasonal_decompose(mysterious_data_1, model='additive')\n",
    "decomposition.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the 2nd dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = seasonal_decompose(mysterious_data_2, model='additive')\n",
    "decomposition.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well.. mysterious data 2 seems more mysterious than mysterious data 1, but this is all very subjective and annoying. Maybe we have a more objective way to look for structure?\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#eb3483'> Similarity with the past </font>\n",
    "\n",
    "We usually create models to forecast based on previous endogenous observations, we say that time series are **autoregressive**, that is, the current prediction is a result of the previous periods.\n",
    "\n",
    "For that kind of modelling, we need to choose how many steps in the past (i.e. lags) our model will consider to produce a prediction. In order to choose how many lags we will use, we have several tools at our disposal. In this section, we will present two of them: lags scatter plot and autocorrelation, both of them visual approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#eb3483'> 1. Lags Scatterplot </font>\n",
    "A very simple way to visually assess the temporal relationships within a time series is through the use of lags scatter: draw a scatter plot between the $y(t)$ and $y(t-lag)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import lag_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysterious_data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_plot(mysterious_data_1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_plot(mysterious_data_1, lag=6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_plot(mysterious_data_1, lag=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there is some correlation for a lag of 12 months, which makes sense since annual cycles are the most common ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#eb3483'> 2. ACF </font>\n",
    "\n",
    "ACF stands for Auto Correlation Function.\n",
    "\n",
    "\n",
    "The idea, in plain English, is very simple: \"how correlated is each datapoint, to the datapoints lagged x periods?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color='#eb3483'>  2.1 ACF by hand </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysterious_data_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we lag the dataset by 1 period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystery_lag_1 = mysterious_data_1.shift(1)\n",
    "mystery_lag_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So... the data that was at 1971-01-01 is now at 1971-02-01, and so on and so forth. Fancy.\n",
    "\n",
    "How correlated are mystery and mystery_lag_1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysterious_data_1.corr(mysterious_data_1.shift(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok... how about if we lag it two times? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysterious_data_1.corr(mysterious_data_1.shift(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negatively correlated. Let's get a bunch of these, for different values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = {}\n",
    "for lag in range(40):\n",
    "    corrs[lag] = mysterious_data_1.corr(mysterious_data_1.shift(lag))\n",
    "    \n",
    "pd.Series(corrs).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(corrs).plot(kind='bar')\n",
    "sns.mpl.pyplot.xlabel('Lag')\n",
    "sns.mpl.pyplot.ylabel('Correlation between original and lagged series');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wooow! We can see the structure! Every 12 months (year!) we get really high correlation, and maybe even some yearly seasons here. Cool bananas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#eb3483'> 2.2 ACF with stats model </font>\n",
    "\n",
    "ACF is so useful, that `statsmodel` actually comes with functions to calculate and to draw them. It also gives you something super useful, which are pre-calculated confidence intervals to get an idea of how significant the auto-correlation is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf\n",
    "from statsmodels.graphics.tsaplots import plot_acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acf(mysterious_data_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is what we did manually. We can also get a fancy plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(mysterious_data_1, alpha=.05)\n",
    "sns.mpl.pyplot.xlabel('lag')\n",
    "sns.mpl.pyplot.ylabel('Autocorrelation');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shaded area in the chart above is the confidence bound. By passing the parameter alpha=0.05 we told the plot to give us the 95% confidence interval.\n",
    "\n",
    "(Remember! If you're 95% confident, then you're going to be wrong once every 20 times, so take the confidence interval with that pinch of salt.)\n",
    "\n",
    "By looking at this plot we can tell that there is some clear seasonal behavior, and that it is quite significant around the 12 mark.\n",
    "\n",
    "What happens if there is no structure?\n",
    "So, we said this helped find structure. What happens if we apply this to the sneaky looking mysterious_data_2?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(mysterious_data_2, alpha=.05)\n",
    "sns.mpl.pyplot.xlabel('lag')\n",
    "sns.mpl.pyplot.ylabel('Autocorrelation');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is how you know that noise, is noise :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color='#eb3483'> 3. PACF </font>\n",
    "\n",
    "[PACF](https://stats.stackexchange.com/questions/129052/acf-and-pacf-formula/129374#129374) stands for Partial Auto Correlation Function.\n",
    "\n",
    "To illustrate the point of this, I'm going to plot the old ACF for `mysterious_data_1`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(mysterious_data_1, alpha=.05)\n",
    "sns.mpl.pyplot.xlabel('lag')\n",
    "sns.mpl.pyplot.ylabel('Autocorrelation');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isn't there something annoying about this plot? Lag 12 has a high auto-correlation. But so does lag 24. And lag 36.  So we're kind of \"recycling\" auto-correlation from the previous year. \n",
    "\n",
    "Walk into a room and tell your boss the following, and you might rightfully be laughed at:\n",
    "> _\"I've found something! The patterm seems to happen ever week, and every two weeks, and every 3 weeks, and every 4 weeks!\"_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import pacf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(mysterious_data_1, alpha=.05, method='ywmle')\n",
    "sns.mpl.pyplot.xlabel('lag')\n",
    "sns.mpl.pyplot.ylabel('Autocorrelation');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, much better. Easier to isolate that 12. And, by the way, why the hell are we looking at 100 months...? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(mysterious_data_1, alpha=.05, lags=40, method='ywmle')\n",
    "sns.mpl.pyplot.xlabel('lag')\n",
    "sns.mpl.pyplot.ylabel('Autocorrelation');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>\n",
    "\n",
    "##  <font color='#eb3483'> In search of stationarity </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is stationarity? \n",
    "\n",
    "> **_\"A stationary time series is one whose statistical properties such as mean, variance, autocorrelation, etc. are all constant over time.\"_**\n",
    "\n",
    "Stationarity is a holy grail in timeseries, specially if you are using the type of models we will show you next. If a process is stationary, then you can make cool predictions. We can (and will) transform our timeseries until they are stationary processes.\n",
    "\n",
    "First, let's look at a clearly non stationary timeseries , a dataset containing tractor sales by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('data/Tractor-Sales.csv')['Number of Tractor Sold']\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is the mean constant over time?**\n",
    "Nope.\n",
    "\n",
    "**Is the variance constant over time?**\n",
    "Oh hell no.\n",
    "\n",
    "**Is the auto-correlation constant over time?**\n",
    "Probably not..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's beat this timeseries into submission until it becomes stationary! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color='#eb3483'> Removing trend </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we can clearly see in this timeseries is that it has a trend. A trivial way to remove the trend is to take the lag 1, and subtract it. In other words, instad of using the series, we will use the difference beween consecutive observations. \n",
    "\n",
    "Difference, you say? difference... Ah! [Diff!](http://pandas.pydata.org/pandas-docs/version/0.17/generated/pandas.Series.diff.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_diff = sales.diff(periods=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_diff.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_diff.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks more stable, but its not stationary yet, because the variance is growing with time. \n",
    "\n",
    "We can take care of that by applying a log transform to the data. \n",
    "\n",
    "(**Note**: *we will do the log transform first, and then the diff. The reason is that the diff has a tendency to place results at zero, which will prove problematic with the log transform*. \n",
    "\n",
    "*So please notice: this is being performed on the original dataset, not on sales_diff.* )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_logged = sales.map(np.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this look like? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.plot(legend='Original', ls=':')\n",
    "sales_logged.plot(figsize=(16, 5), secondary_y=True)\n",
    "sns.mpl.pyplot.title('Logged sales (original sales dotted)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the variance in the original timeseries kept growing, but our logged timeseries has constant variance! \n",
    "\n",
    "Now we can diff it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_logged_diff = sales_logged.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_logged_diff.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm... mean looks constant over time, variance seems constant over time... looks like we managed! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was clearly an easy timeseries to make stationary. Most timeseries require a lot more work. There are approaches such as removing a moving average that are more powerful, and tend to work quite well. \n",
    "\n",
    "However, remember this: whatever transformation you do to your timeseries in your attempt to make it stationary should be one you can reverse later. If your boss asks you \n",
    "> _\"How many tractors are we doing to sell in 3 weeks?\"_\n",
    "\n",
    "\n",
    "Answering this won't get you far: \n",
    "> _\"On that week, I predict a logged diff of -0.23.\"_\n",
    "\n",
    "So whenever you are transforming your timeseries, you need to keep these transformations reversible, and the more complex the transformation, the more complex it is to invert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color='#eb3483'> Evaluating stationarity </font>\n",
    "\n",
    "Is it stationary? It... \"looks stationary\". \n",
    "\n",
    "A robust method to assess stationarity is to use the **[Dickey-Fuller test](http://www.statsmodels.org/dev/generated/statsmodels.tsa.stattools.adfuller.html#statsmodels.tsa.stattools.adfuller)**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dickey-Fuller test is a statistical test where the null hypothesis is that the [Unit Root](https://en.wikipedia.org/wiki/Unit_root) is present. The details of this are interesting yet out of scope, but suffice it to say for our purposes that if the unit root isn't present, the timeseries can be assumed to be stationary. \n",
    "\n",
    "So, for the time being, _\"Unit Root is bad\"_, and _\"no Unit Root is good\"_. If the pvalue is above a critical size, then we cannot reject that there is a unit root. \n",
    " \n",
    " So... we want a low p value. Got that? Great. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adfuller(sales_logged_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems our series has missing data, basically because when you diff the first n elements (with n being the lag) are null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_logged_diff.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute it again without the nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adfstat, pvalue, usedlag, nobs, critvalues, icbest = adfuller(sales_logged_diff.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, I know, so many returns. It's worth taking a look at [the documentation](http://www.statsmodels.org/dev/generated/statsmodels.tsa.stattools.adfuller.html#statsmodels.tsa.stattools.adfuller), but for our purposes, we're going to use it in a ridiculously simple way: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Statistic: %0.02f' % adfstat)\n",
    "print('pvalue:    %0.03f' % pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p value is low, but not as low as we'd like it to be. We can't reject that we have unit root at a 95% confidence interval, which is where we like to have these things. So the timeseries is not statistically stationary\n",
    "\n",
    "How about we diff one more time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_logged_and_diffed_twice = sales_logged_diff.diff().dropna() # taking a second diff \n",
    "adfstat, pvalue, usedlag, nobs, critvalues, icbest = adfuller(sales_logged_and_diffed_twice)\n",
    "print('Statistic: %0.02f' % adfstat)\n",
    "print('pvalue:    %0.03f' % pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_logged_and_diffed_twice.plot();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
